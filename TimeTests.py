def time_test():
  def report():
    clear()
    print("min: %.6f %.6f" % (td_min, td2_min))
    print("%.6f %.6f" % res)

  data = tuple((0, "5") for i in range(100000))
  td_sum = td2_sum = count = 0
  td_min = td2_min = float("inf")

  while True:
    check = (lambda value: None,)
    T = time()
    for TypeV, value in data:
      check[TypeV](value)
    td = time() - T

    check = (None,)
    T = time()
    for TypeV, value in data:
      func = check[TypeV]
      if func is not None: func(value)
    td2 = time() - T

    res = td, td2
    # Замечен факт: чем больше операций после замеряемых по времени участков,
    # тем выше трудоёмкость самих участков. Может это и не логично,
    # но, предположительно, нагрузка на Java-мусоросборщик влияет на ВЕСЬ код

    td_min  = min(td_min, td)
    td2_min = min(td2_min, td2)

    # print(td, td2) # 0.8 vs 0.04 (вызов пустой функции в 20 раз дороже, чем проверка на None)

    """
После ОЧЕНЬ серьёзной оптимизационной работы моего py-движка:
  редизайн виртуального процессора с упором на уменьшения числа dalvik-операций;
  регистры и scope-области выделяются теперь заранее;
  в обработчике аргументов, регистры только очищаются через Arrays.fill(regs, null);
  обработчик аргументов написан более осознанно и теперь менее требовательный;
  в 1000 раз теперь понятнее, как В БУДУЩЕМ реализовать yield и gen_expr-механику
    """
    # print(*res)    # 0.049 vs 0.0418 (x17 к скорости вызова пустой функции!!!)

    """
После оптимизации лишних переходов регистров:
  к сожалению, это ещё не идеальный вариант, т.к. для идеального,
  пришлось бы строить полноценный граф управления программы;
  теперь все константы выгружаются в регистры в самом начале каждой функции;
  все регистры и локальные переменные объеденены в регистры
    """
    # print(*res)    # 0.0405 vs 0.0267 (x1.5 к скорости обычного выполнения)

    """
После оптимизации самого исполнительного ядра:
  сильно поменялся дизайн исполнителя: уменьшено количество dalvik-операций по максимуму;
  range теперь имеет ускоренную версию range-int за счёт int вместо BigInteger
    """
    # print(*res)    # 0.0372 vs 0.0289 (странненько, они приблизились)

    """
Оптимизация концепции builtins, globals, consts и locals:
  построена обобщёная схема всех команд виртуального процессора;
  за счёт этой схемы, исправлены некоторые ошибки оптимизатора;
  вместо отдельного globals, теперь, вместо него, locals модуля;
  bultins и globals теперь объеденены;
  константы загружаются в регистры теперь на этапе объявления функции, а не прямо внутри тела функции
    """

    # report()    # 0.0326 vs 0.0277 (функции работают ещё чуть-быстрее)

    """
Просто пометил в AndroidManifest приложение, как "игра":
  автоматически включается Hyperboost realme для ускорения
    """

    # report()    # 0.02821 vs 0.02129 (почти обогнал функции оригинального питона)

    report()

    # print(100000 / td, 100000 / td2)

# замеры на QPython3 (это же устройство):
#    0.02744 vs 0.0112
# я довольно-таки близок к тому, чтобы обогнать его!
# при том QPython3 на .so-библиотеке, т.е. это тот же CPython, а у меня - чистая Java

def time_test2():
  while True:
    T = time()
    for i in range(1000000): pass
    print(1000000 / (time() - T))

Thread(time_test).start()
